#!/usr/bin/env python3
"""
é¢è¯•è¾…åŠ©å·¥å…· - macOS åŒé€šé“è¯­éŸ³è¯†åˆ«
åŒæ—¶æ•è·æ‰¬å£°å™¨ï¼ˆé¢è¯•å®˜ï¼‰å’Œéº¦å…‹é£ï¼ˆä½ ï¼‰

é‡æ„ç‰ˆæœ¬ - æ¨¡å—åŒ–ã€æ¸…æ™°ã€æ˜“ç»´æŠ¤
"""

import sys
import signal
import time
import queue
import threading

from config import AUDIO_QUEUE_MAX_SIZE
from config import TENCENT_SECRET_ID, TENCENT_SECRET_KEY, TENCENT_APP_ID
from config import TENCENT_ENGINE_MODEL_TYPE, TENCENT_REGION
from config import LLM_PROVIDER
from config import QWEN_API_KEY, QWEN_MODEL, QWEN_BASE_URL
from config import OPENAI_API_KEY, OPENAI_MODEL, OPENAI_BASE_URL
from config import ANTHROPIC_API_KEY, ANTHROPIC_MODEL
from audio_device import AudioDeviceManager
from audio_capture import start_capture_thread
from speech_recognizer import start_recognizer_thread
from keyboard_listener import start_keyboard_listener
from asr_backend import TencentASR
from llm import LLMProvider, LLMAssistant


class InterviewAssistant:
    """é¢è¯•è¾…åŠ©å·¥å…·ä¸»ç±» - åè°ƒå„ä¸ªæ¨¡å—"""
    
    def __init__(self):
        self.stop_event = threading.Event()
        self.audio_queue = None
        self.threads = []
        self.speaker_device = None
        self.microphone_device = None
        self.recognizer = None  # è¯­éŸ³è¯†åˆ«å™¨ï¼ˆç”¨äºè·å–æœ€æ–°è¯†åˆ«ç»“æœï¼‰
        self.llm_assistant = None  # LLM åŠ©æ‰‹
    
    def setup_signal_handler(self):
        """æ³¨å†Œä¿¡å·å¤„ç†å™¨"""
        signal.signal(signal.SIGINT, self._signal_handler)
    
    def _signal_handler(self, sig, frame):
        """å¤„ç† Ctrl+C ä¿¡å·"""
        print("\n\næ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
        self.stop_event.set()
    
    def detect_devices(self) -> bool:
        """
        æ£€æµ‹éŸ³é¢‘è®¾å¤‡
        
        Returns:
            True if successful, False otherwise
        """
        print("\n[1/3] æ£€æµ‹éŸ³é¢‘æ•è·è®¾å¤‡...")
        self.speaker_device, self.microphone_device = AudioDeviceManager.get_best_devices()
        
        if self.speaker_device is None:
            print("\nâŒ è‡³å°‘éœ€è¦æ‰¬å£°å™¨æ•è·è®¾å¤‡æ‰èƒ½è¿è¡Œ")
            return False
        
        return True
    
    def initialize_recognizer(self) -> bool:
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
        
        Returns:
            True if successful, False otherwise
        """
        print("\n[2/3] åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«...")
        
        # åˆ›å»ºè…¾è®¯äº‘ ASR
        try:
            asr_backend = TencentASR(
                secret_id=TENCENT_SECRET_ID,
                secret_key=TENCENT_SECRET_KEY,
                app_id=TENCENT_APP_ID,
                engine_model_type=TENCENT_ENGINE_MODEL_TYPE,
                region=TENCENT_REGION
            )
        except Exception as e:
            print(f"âŒ è…¾è®¯äº‘ ASR åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
        
        # åˆ›å»ºå…±äº«é˜Ÿåˆ—
        self.audio_queue = queue.Queue(maxsize=AUDIO_QUEUE_MAX_SIZE)
        
        # å¯åŠ¨è¯†åˆ«çº¿ç¨‹
        thread, recognizer = start_recognizer_thread(
            self.audio_queue,
            self.stop_event,
            asr_backend
        )
        
        if thread is None:
            return False
        
        self.threads.append(thread)
        self.recognizer = recognizer  # ä¿å­˜è¯†åˆ«å™¨å¼•ç”¨
        return True
    
    def initialize_llm(self) -> bool:
        """
        åˆå§‹åŒ– LLM åŠ©æ‰‹
        
        Returns:
            True if successful, False otherwise
        """
        print("\nåˆå§‹åŒ– LLM åŠ©æ‰‹...")
        
        try:
            # æ ¹æ®é…ç½®é€‰æ‹© LLM æä¾›å•†
            if LLM_PROVIDER == "qwen":
                if not QWEN_API_KEY:
                    print("âš ï¸  æœªé…ç½® Qwen API Keyï¼Œè·³è¿‡ LLM åˆå§‹åŒ–")
                    return False
                
                provider = LLMProvider(
                    api_key=QWEN_API_KEY,
                    model=QWEN_MODEL,
                    base_url=QWEN_BASE_URL
                )
                print(f"  ä½¿ç”¨ Qwen {QWEN_MODEL}")
                print(f"  API åœ°å€: {QWEN_BASE_URL}")
            
            elif LLM_PROVIDER == "openai":
                if OPENAI_API_KEY == "YOUR_OPENAI_API_KEY_HERE" or not OPENAI_API_KEY:
                    print("âš ï¸  æœªé…ç½® OpenAI API Keyï¼Œè·³è¿‡ LLM åˆå§‹åŒ–")
                    print("   åœ¨ config.py ä¸­è®¾ç½® OPENAI_API_KEY")
                    return False
                
                provider = LLMProvider(
                    api_key=OPENAI_API_KEY,
                    model=OPENAI_MODEL,
                    base_url=OPENAI_BASE_URL or "https://api.openai.com/v1"
                )
                print(f"  ä½¿ç”¨ OpenAI {OPENAI_MODEL}")
            
            else:
                print(f"âŒ æœªçŸ¥çš„ LLM æä¾›å•†: {LLM_PROVIDER}")
                print(f"   æ”¯æŒçš„æä¾›å•†: qwen, openai")
                return False
            
            self.llm_assistant = LLMAssistant(provider)
            print("âœ“ LLM åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆ")
            return True
        
        except Exception as e:
            print(f"âš ï¸  LLM åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def start_capture(self):
        """å¯åŠ¨éŸ³é¢‘æ•è·çº¿ç¨‹"""
        print("\n[3/3] å¯åŠ¨éŸ³é¢‘å¤„ç†çº¿ç¨‹...")
        
        # å¯åŠ¨æ‰¬å£°å™¨æ•è·
        speaker_thread = start_capture_thread(
            self.audio_queue,
            self.speaker_device,
            'speaker',
            self.stop_event
        )
        if speaker_thread:
            self.threads.append(speaker_thread)
        
        # å¯åŠ¨éº¦å…‹é£æ•è·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.microphone_device is not None:
            mic_thread = start_capture_thread(
                self.audio_queue,
                self.microphone_device,
                'microphone',
                self.stop_event
            )
            if mic_thread:
                self.threads.append(mic_thread)
    
    def on_ctrl_v_pressed(self):
        """Ctrl+V æŒ‰ä¸‹æ—¶çš„å›è°ƒå‡½æ•° - å‘é€é—®é¢˜ç»™ AI"""
        if self.recognizer is None or self.llm_assistant is None:
            return
        
        # è·å–æœ€æ–°çš„é¢è¯•å®˜é—®é¢˜
        question = self.recognizer.last_speaker_text
        
        if not question:
            print("\nâš ï¸  æ²¡æœ‰æ•è·åˆ°é¢è¯•å®˜çš„é—®é¢˜")
            return
        
        # æ˜¾ç¤º AI å›å¤
        print("\n" + "="*60)
        print(f"ğŸ“ é¢è¯•å®˜é—®é¢˜ï¼š{question}")
        print("-"*60)
        print("ğŸ¤– AI å»ºè®®ï¼š")
        
        try:
            # æµå¼è¾“å‡º AI å›å¤
            for chunk in self.llm_assistant.chat_stream(question):
                print(chunk, end='', flush=True)
            print("\n" + "="*60 + "\n")
        
        except KeyboardInterrupt:
            print("\n\nâš ï¸  AI å›å¤è¢«ä¸­æ–­\n")
        except Exception as e:
            print(f"\n\nâŒ AI å›å¤å¤±è´¥: {e}\n")
    
    def print_status(self):
        """æ‰“å°ç³»ç»ŸçŠ¶æ€"""
        print("\n" + "="*60)
        print("âœ“ ç³»ç»Ÿå°±ç»ªï¼")
        print("  ğŸ”Š ç›‘å¬æ‰¬å£°å™¨ï¼šæ•è·é¢è¯•å®˜è¯­éŸ³")
        if self.microphone_device:
            print("  ğŸ™ï¸  ç›‘å¬éº¦å…‹é£ï¼šæ•è·ä½ çš„è¯­éŸ³")
        
        if self.llm_assistant:
            print("\n  ğŸ¤– AI åŠ©æ‰‹ï¼šå·²å¯ç”¨")
            print("     æŒ‰ Ctrl+V å‘é€é—®é¢˜ç»™ AI")
        
        print("\næç¤ºï¼šå¼€å§‹é¢è¯•æˆ–æ’­æ”¾æµ‹è¯•éŸ³é¢‘")
        print("æŒ‰ Ctrl+C åœæ­¢")
        print("="*60 + "\n")
    
    def wait_for_stop(self):
        """ç­‰å¾…é€€å‡ºä¿¡å·"""
        try:
            while not self.stop_event.is_set():
                time.sleep(0.5)
        except KeyboardInterrupt:
            print("\næ”¶åˆ°é”®ç›˜ä¸­æ–­")
            self.stop_event.set()
    
    def cleanup(self):
        """æ¸…ç†èµ„æºï¼Œç­‰å¾…çº¿ç¨‹é€€å‡º"""
        print("\nç­‰å¾…æ‰€æœ‰çº¿ç¨‹é€€å‡º...")
        
        for thread in self.threads:
            thread.join(timeout=5)
            if thread.is_alive():
                print(f"âš ï¸  çº¿ç¨‹ {thread.name} æœªèƒ½æ­£å¸¸é€€å‡º")
        
        print("âœ“ æ‰€æœ‰çº¿ç¨‹å·²é€€å‡º")
        print("\nç¨‹åºç»“æŸ")
    
    def run(self) -> int:
        """
        ä¸»è¿è¡Œæµç¨‹
        
        Returns:
            exit code (0 = success, 1 = error)
        """
        print("="*60)
        print("  é¢è¯•è¾…åŠ©å·¥å…· - åŒé€šé“è¯­éŸ³è¯†åˆ«")
        print("  åŒæ—¶ç›‘å¬ï¼šæ‰¬å£°å™¨ï¼ˆé¢è¯•å®˜ï¼‰+ éº¦å…‹é£ï¼ˆä½ ï¼‰")
        print("="*60)
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        self.setup_signal_handler()
        
        # 1. æ£€æµ‹è®¾å¤‡
        if not self.detect_devices():
            return 1
        
        # 2. åˆå§‹åŒ–è¯†åˆ«å™¨
        if not self.initialize_recognizer():
            return 1
        
        # 2.5. åˆå§‹åŒ– LLMï¼ˆå¯é€‰ï¼‰
        self.initialize_llm()
        
        # 3. å¯åŠ¨æ•è·
        self.start_capture()
        
        # 4. å¯åŠ¨é”®ç›˜ç›‘å¬ï¼ˆå¦‚æœ LLM å¯ç”¨ï¼‰
        if self.llm_assistant:
            keyboard_thread = start_keyboard_listener(
                self.on_ctrl_v_pressed,
                self.stop_event
            )
            if keyboard_thread:
                self.threads.append(keyboard_thread)
        
        # ç­‰å¾…çº¿ç¨‹å¯åŠ¨
        time.sleep(1)
        
        # 4. æ‰“å°çŠ¶æ€
        self.print_status()
        
        # 5. ç­‰å¾…é€€å‡º
        self.wait_for_stop()
        
        # 6. æ¸…ç†
        self.cleanup()
        
        return 0


def main():
    """ç¨‹åºå…¥å£"""
    assistant = InterviewAssistant()
    return assistant.run()


if __name__ == "__main__":
    sys.exit(main())

