"""
éŸ³é¢‘æ•è· - ç”Ÿäº§è€…çº¿ç¨‹
èŒè´£ï¼šä»éŸ³é¢‘è®¾å¤‡è¯»å–æ•°æ®ï¼Œæ£€æµ‹è¯­éŸ³æ´»åŠ¨ï¼Œæ”¾å…¥é˜Ÿåˆ—
"""

import pyaudio
import numpy as np
import time
import queue
import threading
from typing import Literal

from config import (
    FORMAT, RATE, CHUNK_DURATION, MAX_BUFFER_DURATION,
    SILENCE_DURATION, SILENCE_THRESHOLD, DEBUG_MODE
)
from audio_device import DeviceInfo
from audio_processor import AudioProcessor, AudioChunk


class AudioCaptureThread:
    """
    éŸ³é¢‘æ•è·çº¿ç¨‹ - åŸºäº VAD (Voice Activity Detection) çš„æ™ºèƒ½æ•è·
    
    å·¥ä½œåŸç†ï¼š
    1. æŒç»­è¯»å–éŸ³é¢‘å—
    2. æ£€æµ‹åˆ°å£°éŸ³ â†’ å¼€å§‹ç¼“å†²
    3. æ£€æµ‹åˆ°é™éŸ³æŒç»­ SILENCE_DURATION ç§’ â†’ å¤„ç†å¹¶å‘é€
    4. ç¼“å†²è¶…è¿‡ MAX_BUFFER_DURATION ç§’ â†’ å¼ºåˆ¶å¤„ç†
    """
    
    # å…±äº« PyAudio å¯¹è±¡ï¼ˆé¿å… macOS å¤šçº¿ç¨‹ bugï¼‰
    _shared_pyaudio = None
    _pyaudio_lock = threading.Lock()
    
    def __init__(
        self,
        audio_queue: queue.Queue,
        device_info: DeviceInfo,
        source_type: Literal['speaker', 'microphone'],
        stop_event: threading.Event
    ):
        self.audio_queue = audio_queue
        self.device_info = device_info
        self.source_type = source_type
        self.stop_event = stop_event
        
        # è®¡ç®—å‚æ•°
        self.chunk_size = int(device_info.sample_rate * CHUNK_DURATION)
        self.silence_chunks_needed = int(SILENCE_DURATION / CHUNK_DURATION)
        
        # æ˜¾ç¤ºæ ‡ç­¾
        self.label = "ğŸ”Š æ‰¬å£°å™¨" if source_type == 'speaker' else "ğŸ™ï¸  éº¦å…‹é£"
    
    @classmethod
    def _get_shared_pyaudio(cls):
        """è·å–å…±äº«çš„ PyAudio å¯¹è±¡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with cls._pyaudio_lock:
            if cls._shared_pyaudio is None:
                cls._shared_pyaudio = pyaudio.PyAudio()
            return cls._shared_pyaudio
    
    def run(self):
        """çº¿ç¨‹ä¸»å¾ªç¯"""
        print(f"\n{self.label} ç”Ÿäº§è€…çº¿ç¨‹å¯åŠ¨:")
        print(f"  è®¾å¤‡: {self.device_info.name}")
        print(f"  é‡‡æ ·ç‡: {self.device_info.sample_rate} Hz")
        print(f"  é€šé“æ•°: {self.device_info.channels}")
        print(f"  é™éŸ³æ£€æµ‹: {SILENCE_DURATION}ç§’é™éŸ³åå¤„ç†")
        
        p = self._get_shared_pyaudio()
        
        try:
            stream = p.open(
                format=FORMAT,
                channels=self.device_info.channels,
                rate=self.device_info.sample_rate,
                input=True,
                input_device_index=self.device_info.index,
                frames_per_buffer=self.chunk_size
            )
            
            # VAD çŠ¶æ€
            audio_buffer = []
            buffer_duration = 0
            silence_chunks_count = 0
            is_speaking = False
            
            while not self.stop_event.is_set():
                try:
                    # è¯»å–éŸ³é¢‘
                    data = stream.read(self.chunk_size, exception_on_overflow=False)
                    audio_data = np.frombuffer(data, dtype=np.int16)
                    
                    # è½¬å•å£°é“
                    audio_data = AudioProcessor.to_mono(audio_data, self.device_info.channels)
                    
                    # å½’ä¸€åŒ–
                    audio_float = AudioProcessor.normalize(audio_data)
                    
                    # é™éŸ³æ£€æµ‹
                    is_silent = AudioProcessor.is_silent(audio_float, SILENCE_THRESHOLD)
                    
                    if not is_silent:
                        # æœ‰å£°éŸ³
                        if not is_speaking:
                            is_speaking = True
                        silence_chunks_count = 0
                        audio_buffer.append(audio_data)
                        buffer_duration += len(audio_data) / self.device_info.sample_rate
                    else:
                        # é™éŸ³
                        if is_speaking:
                            silence_chunks_count += 1
                            audio_buffer.append(audio_data)
                            buffer_duration += len(audio_data) / self.device_info.sample_rate
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
                    should_process = False
                    if is_speaking and silence_chunks_count >= self.silence_chunks_needed:
                        should_process = True
                    elif is_speaking and buffer_duration >= MAX_BUFFER_DURATION:
                        should_process = True
                    
                    if should_process and len(audio_buffer) > 0:
                        if DEBUG_MODE:
                            print(f"[{self.label}] æ£€æµ‹åˆ°å®Œæ•´è¯­éŸ³ç‰‡æ®µï¼Œæ—¶é•¿: {buffer_duration:.2f}ç§’ï¼Œå¼€å§‹å¤„ç†...")
                        
                        self._process_buffer(audio_buffer, buffer_duration)
                        
                        # é‡ç½®çŠ¶æ€
                        audio_buffer = []
                        buffer_duration = 0
                        silence_chunks_count = 0
                        is_speaking = False
                
                except Exception as e:
                    if not self.stop_event.is_set():
                        print(f"âš ï¸  [{self.label}] è¯»å–éŸ³é¢‘å¤±è´¥: {e}")
                    break
        
        except Exception as e:
            print(f"âŒ [{self.label}] çº¿ç¨‹å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
        finally:
            try:
                stream.stop_stream()
                stream.close()
            except:
                pass
            # ä¸ terminate å…±äº«çš„ PyAudio å¯¹è±¡ï¼ˆå…¶ä»–çº¿ç¨‹å¯èƒ½è¿˜åœ¨ä½¿ç”¨ï¼‰
            print(f"âœ“ [{self.label}] ç”Ÿäº§è€…çº¿ç¨‹å·²é€€å‡º")
    
    def _process_buffer(self, audio_buffer: list, buffer_duration: float):
        """
        å¤„ç†ç¼“å†²çš„éŸ³é¢‘æ•°æ®
        
        æµç¨‹ï¼š
        1. æ‹¼æ¥æ‰€æœ‰éŸ³é¢‘å—
        2. é‡é‡‡æ ·åˆ° 16kHz
        3. å½’ä¸€åŒ–
        4. åˆ›å»º AudioChunk
        5. æ”¾å…¥é˜Ÿåˆ—
        """
        process_start = time.time()
        
        # æ‹¼æ¥
        full_audio = np.concatenate(audio_buffer)
        
        # é‡é‡‡æ ·
        if self.device_info.sample_rate != RATE:
            full_audio = AudioProcessor.resample(
                full_audio,
                self.device_info.sample_rate,
                RATE
            )
        
        # å½’ä¸€åŒ–
        audio_float32 = AudioProcessor.normalize(full_audio)
        
        # åˆ›å»º AudioChunk
        chunk = AudioChunk(
            source=self.source_type,
            audio_data=audio_float32,
            timestamp=time.time(),
            duration=buffer_duration
        )
        
        process_elapsed = time.time() - process_start
        
        if DEBUG_MODE:
            print(f"[{self.label}] éŸ³é¢‘å¤„ç†å®Œæˆï¼Œè€—æ—¶: {process_elapsed:.3f}ç§’ï¼Œæ”¾å…¥é˜Ÿåˆ—...")
        
        # æ”¾å…¥é˜Ÿåˆ—ï¼ˆé˜Ÿåˆ—æ»¡åˆ™ä¸¢å¼ƒæœ€æ—§çš„ï¼‰
        try:
            self.audio_queue.put_nowait(chunk)
            if DEBUG_MODE:
                print(f"[{self.label}] å·²æ”¾å…¥é˜Ÿåˆ—ï¼Œé˜Ÿåˆ—å¤§å°: {self.audio_queue.qsize()}")
        except queue.Full:
            if DEBUG_MODE:
                print(f"[{self.label}] é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæœ€æ—§æ•°æ®")
            try:
                self.audio_queue.get_nowait()
                self.audio_queue.put_nowait(chunk)
            except queue.Empty:
                pass


def start_capture_thread(
    audio_queue: queue.Queue,
    device_info: DeviceInfo,
    source_type: Literal['speaker', 'microphone'],
    stop_event: threading.Event
) -> threading.Thread:
    """
    å¯åŠ¨éŸ³é¢‘æ•è·çº¿ç¨‹çš„å·¥å‚å‡½æ•°
    
    Returns:
        å·²å¯åŠ¨çš„çº¿ç¨‹å¯¹è±¡
    """
    if device_info is None:
        print(f"âŒ [{source_type}] æ²¡æœ‰å¯ç”¨çš„æ•è·è®¾å¤‡")
        return None
    
    capture = AudioCaptureThread(audio_queue, device_info, source_type, stop_event)
    
    thread = threading.Thread(
        target=capture.run,
        daemon=False,
        name=f"{source_type.capitalize()}Producer"
    )
    thread.start()
    
    return thread

