"""
è¯­éŸ³è¯†åˆ« - æ¶ˆè´¹è€…çº¿ç¨‹
èŒè´£ï¼šä»é˜Ÿåˆ—å–å‡ºéŸ³é¢‘ï¼Œè¿›è¡Œ ASRï¼Œè¾“å‡ºç»“æœ
"""

import queue
import threading
import time

from config import MAX_CONSECUTIVE_ERRORS, SILENCE_THRESHOLD, DEBUG_MODE, SHOW_TIMING
from audio_processor import AudioChunk, AudioProcessor


class SpeechRecognizer:
    """è¯­éŸ³è¯†åˆ«å™¨ - æ¶ˆè´¹è€…çº¿ç¨‹ï¼ˆä½¿ç”¨è…¾è®¯äº‘ ASRï¼‰"""
    
    def __init__(
        self,
        audio_queue: queue.Queue,
        stop_event: threading.Event,
        asr_backend,
        on_result_callback=None
    ):
        self.audio_queue = audio_queue
        self.stop_event = stop_event
        self.asr_backend = asr_backend
        self.consecutive_errors = 0
        self.on_result_callback = on_result_callback  # GUI å›è°ƒå‡½æ•°
        
        # ç¼“å­˜æœ€æ–°çš„è¯†åˆ«ç»“æœ
        self.last_speaker_text = ""  # é¢è¯•å®˜æœ€åè¯´çš„è¯
        self.last_speaker_timestamp = 0  # æ—¶é—´æˆ³
    
    def run(self):
        """æ¶ˆè´¹è€…çº¿ç¨‹ä¸»å¾ªç¯"""
        print("æ¶ˆè´¹è€…çº¿ç¨‹å¯åŠ¨ï¼Œç­‰å¾…éŸ³é¢‘æ•°æ®...")
        
        while not self.stop_event.is_set():
            try:
                # é˜»å¡ç­‰å¾…é˜Ÿåˆ—æ•°æ®
                try:
                    chunk = self.audio_queue.get(timeout=0.5)
                except queue.Empty:
                    continue
                
                # éªŒè¯æ•°æ®ç±»å‹
                if not isinstance(chunk, AudioChunk):
                    print("âš ï¸  æ”¶åˆ°éæ³•æ•°æ®ç±»å‹")
                    self.audio_queue.task_done()
                    continue
                
                # å¤„ç†éŸ³é¢‘
                self._process_chunk(chunk)
                self.audio_queue.task_done()
            
            except Exception as e:
                if not self.stop_event.is_set():
                    print(f"âŒ æ¶ˆè´¹è€…çº¿ç¨‹å¼‚å¸¸: {e}")
                    import traceback
                    traceback.print_exc()
                break
        
        print("âœ“ æ¶ˆè´¹è€…çº¿ç¨‹å·²é€€å‡º")
    
    def _process_chunk(self, chunk: AudioChunk):
        """
        å¤„ç†å•ä¸ªéŸ³é¢‘å—
        
        æµç¨‹ï¼š
        1. éªŒè¯éŸ³é¢‘æ•°æ®
        2. æ£€æŸ¥æ˜¯å¦ä¸ºé™éŸ³
        3. è°ƒç”¨ ASR æ¨¡å‹
        4. è¾“å‡ºç»“æœ
        """
        total_start = time.time()
        
        audio_data = chunk.audio_data
        source = chunk.source
        
        # è®¾ç½®æ˜¾ç¤ºæ ‡ç­¾
        label = "ğŸ”Š é¢è¯•å®˜" if source == 'speaker' else "ğŸ™ï¸  æˆ‘"
        
        if DEBUG_MODE:
            queue_delay = total_start - chunk.timestamp
            print(f"[{label}] ä»é˜Ÿåˆ—å–å‡ºéŸ³é¢‘ï¼Œé˜Ÿåˆ—å»¶è¿Ÿ: {queue_delay:.3f}ç§’ï¼ŒéŸ³é¢‘æ—¶é•¿: {chunk.duration:.2f}ç§’")
        
        # éªŒè¯éŸ³é¢‘æ•°æ®
        if not AudioProcessor.validate_audio(audio_data):
            print(f"âš ï¸  [{label}] éŸ³é¢‘æ•°æ®æ— æ•ˆ")
            return
        
        # æ£€æŸ¥é™éŸ³
        if AudioProcessor.is_silent(audio_data, SILENCE_THRESHOLD):
            if DEBUG_MODE:
                print(f"[{label}] éŸ³é¢‘ä¸ºé™éŸ³ï¼Œè·³è¿‡è¯†åˆ«")
            return
        
        # è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼ˆä½¿ç”¨åç«¯ï¼‰
        try:
            asr_start = time.time()
            
            # è°ƒç”¨ ASR åç«¯
            text = self.asr_backend.recognize(audio_data)
            
            asr_elapsed = time.time() - asr_start
            
            # è¾“å‡ºç»“æœ
            if text:
                total_elapsed = time.time() - total_start
                
                # æ ¹æ®æ¥æºæ˜¾ç¤º
                if source == 'speaker':
                    print(f"é¢è¯•å®˜è¯´: {text}")
                    # ç¼“å­˜é¢è¯•å®˜çš„è¯ï¼ˆç”¨äº AI å›å¤ï¼‰
                    self.last_speaker_text = text
                    self.last_speaker_timestamp = time.time()
                    
                    # è°ƒç”¨ GUI å›è°ƒï¼ˆå¦‚æœæœ‰ï¼‰
                    if self.on_result_callback:
                        try:
                            self.on_result_callback('speaker', text, time.time())
                        except Exception as e:
                            print(f"âš ï¸  å›è°ƒå‡½æ•°é”™è¯¯: {e}")
                else:
                    print(f"æˆ‘è¯´: {text}")
                    
                    # è°ƒç”¨ GUI å›è°ƒï¼ˆå¦‚æœæœ‰ï¼‰
                    if self.on_result_callback:
                        try:
                            self.on_result_callback('microphone', text, time.time())
                        except Exception as e:
                            print(f"âš ï¸  å›è°ƒå‡½æ•°é”™è¯¯: {e}")
                
                # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
                if SHOW_TIMING:
                    print(f"  â±ï¸  ASRè€—æ—¶: {asr_elapsed:.2f}ç§’ | æ€»è€—æ—¶: {total_elapsed:.2f}ç§’ | éŸ³é¢‘æ—¶é•¿: {chunk.duration:.2f}ç§’")
                
                self.consecutive_errors = 0
        
        except Exception as e:
            self.consecutive_errors += 1
            print(f"âŒ [{label}] è¯†åˆ«å¤±è´¥ ({self.consecutive_errors}/{MAX_CONSECUTIVE_ERRORS}): {e}")
            
            if self.consecutive_errors >= MAX_CONSECUTIVE_ERRORS:
                print(f"âŒ è¿ç»­å¤±è´¥{MAX_CONSECUTIVE_ERRORS}æ¬¡ï¼Œæ¶ˆè´¹è€…çº¿ç¨‹é€€å‡º")
                self.stop_event.set()


def start_recognizer_thread(
    audio_queue: queue.Queue,
    stop_event: threading.Event,
    asr_backend,
    on_result_callback=None
) -> tuple[threading.Thread, SpeechRecognizer]:
    """
    å¯åŠ¨è¯­éŸ³è¯†åˆ«çº¿ç¨‹çš„å·¥å‚å‡½æ•°
    
    Args:
        audio_queue: éŸ³é¢‘é˜Ÿåˆ—
        stop_event: åœæ­¢äº‹ä»¶
        asr_backend: è…¾è®¯äº‘ ASR å®ä¾‹
        on_result_callback: è¯†åˆ«ç»“æœå›è°ƒå‡½æ•° (source, text, timestamp)
    
    Returns:
        (thread, recognizer) çº¿ç¨‹å¯¹è±¡å’Œè¯†åˆ«å™¨å¯¹è±¡
    """
    recognizer = SpeechRecognizer(audio_queue, stop_event, asr_backend, on_result_callback)
    
    # å¯åŠ¨çº¿ç¨‹
    thread = threading.Thread(
        target=recognizer.run,
        daemon=False,
        name="Consumer"
    )
    thread.start()
    
    return thread, recognizer

